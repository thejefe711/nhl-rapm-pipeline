#!/usr/bin/env python3
"""
Streamlit MVP - Quick hockey analytics frontend.

Rapid prototype using Streamlit for immediate user validation.
"""

import streamlit as st
import pandas as pd
import json
from typing import Dict, Any, List
import os
import duckdb
from pathlib import Path

def get_player_profile(player_id: int) -> Dict[str, Any]:
    """Get player profile from local database."""
    try:
        # Connect to local database
        db_path = Path(__file__).parent / "nhl_canonical.duckdb"
        if not db_path.exists():
            return get_mock_profile(player_id)

        con = duckdb.connect(str(db_path))

        # Get player basic info
        player_info = con.execute("""
            SELECT full_name, games_count
            FROM players
            WHERE player_id = ?
        """, [player_id]).fetchone()

        if not player_info:
            con.close()
            return get_mock_profile(player_id)

        player_name = player_info[0] or f"Player {player_id}"

        # Get RAPM metrics
        rapm_data = con.execute("""
            SELECT metric_name, value, rank, percentile
            FROM apm_results
            WHERE player_id = ? AND season = '20242025'
        """, [player_id]).fetchall()

        metrics = {}
        for metric_name, value, rank, percentile in rapm_data:
            metrics[metric_name] = {
                'value': value,
                'rank': rank,
                'percentile': percentile
            }

        con.close()

        return {
            "player_id": player_id,
            "name": player_name,
            "games_count": player_info[1] or 0,
            "metrics": metrics,
            "data_source": "local_database"
        }

    except Exception as e:
        return get_mock_profile(player_id)

def get_mock_profile(player_id: int) -> Dict[str, Any]:
    """Fallback mock data for demo purposes."""
    return {
        "player_id": player_id,
        "name": f"Player {player_id}",
        "games_count": 0,
        "metrics": {
            "xg_off_rapm_5v5": {"value": 0.5, "rank": None, "percentile": 60},
            "corsi_off_rapm_5v5": {"value": 2.1, "rank": None, "percentile": 65}
        },
        "data_source": "mock_data"
    }

def get_available_players() -> List[Dict]:
    """Get list of players with analytics data."""
    try:
        db_path = Path(__file__).parent / "nhl_canonical.duckdb"
        if not db_path.exists():
            return []

        con = duckdb.connect(str(db_path))

        players = con.execute("""
            SELECT DISTINCT
                p.player_id,
                p.full_name,
                COUNT(ar.metric_name) as metrics_count
            FROM players p
            LEFT JOIN apm_results ar ON p.player_id = ar.player_id AND ar.season = '20242025'
            WHERE ar.metric_name IS NOT NULL
            GROUP BY p.player_id, p.full_name
            ORDER BY p.full_name
            LIMIT 50
        """).fetchall()

        con.close()

        return [
            {"id": p[0], "name": p[1] or f"Player {p[0]}", "metrics": p[2]}
            for p in players
        ]

    except:
        return []

def main():
    st.set_page_config(
        page_title="Hockey Analytics MVP",
        page_icon="ðŸ’",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("Advanced Hockey Analytics MVP")
    st.markdown("*Early access - helping shape the future of hockey stats*")

    # Credibility Notice
    st.warning("""
    **Data Quality Notice:**
    Currently analyzing only 53 games (4% of NHL season).
    Statistics have 20% credibility rating - use for trends, not absolute rankings.
    Full season data (1300 games) will provide 85% credibility.
    """)

    # Navigation
    page = st.sidebar.selectbox(
        "Navigation",
        ["Player Search", "About Analytics", "Roadmap"]
    )

    if page == "Player Search":
        show_player_search()
    elif page == "About Analytics":
        show_analytics_explanation()
    elif page == "Roadmap":
        show_roadmap()

def show_player_search():
    """Player search and profile page."""

    st.header("Player Search")
    st.markdown("Select a player to view their advanced analytics profile.")

    # Get available players
    available_players = get_available_players()

    if available_players:
        # Create dropdown with player names
        player_options = [f"{p['name']} (ID: {p['id']})" for p in available_players]
        player_ids = [p['id'] for p in available_players]

        selected_option = st.selectbox(
            "Choose a player:",
            options=[""] + player_options,
            format_func=lambda x: "Select a player..." if x == "" else x
        )

        if selected_option and selected_option != "":
            # Extract player ID from selection
            selected_index = player_options.index(selected_option)
            player_id = player_ids[selected_index]

            if st.button("Analyze Player", type="primary"):
                with st.spinner("Loading player analytics..."):
                    profile = get_player_profile(player_id)

                display_player_profile(profile)
    else:
        # Fallback to manual ID entry
        st.warning("Could not load player list. Enter player ID manually:")
        player_id = st.number_input("Player ID", min_value=1, value=8478402)

        if st.button("Analyze Player"):
            with st.spinner("Loading player analytics..."):
                profile = get_player_profile(player_id)

            display_player_profile(profile)

def display_player_profile(profile: Dict[str, Any]):
    """Display comprehensive player profile."""

    st.header(f"ðŸ’ {profile.get('name', 'Unknown Player')}")

    # Data source indicator
    data_source = profile.get('data_source', 'unknown')
    if data_source == 'local_database':
        st.success("âœ… Data loaded from analytics database")
    else:
        st.warning("âš ï¸ Using sample data - full analytics coming soon")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Player ID", profile.get('player_id', 'N/A'))

    with col2:
        games_count = profile.get('games_count', 0)
        st.metric("Games Analyzed", games_count if games_count > 0 else "N/A")

    with col3:
        # Credibility indicator
        credibility = 20  # Current system credibility
        st.metric("Credibility Rating", f"{credibility}%")

        if credibility < 30:
            st.caption("Developing - Use for trends only")
        elif credibility < 70:
            st.caption("Moderate - Good for analysis")
        else:
            st.caption("High - Very reliable")

    st.divider()

    # RAPM Metrics Section
    st.subheader("RAPM Metrics (Regularized Adjusted Plus-Minus)")

    metrics = profile.get('metrics', {})

    if metrics:
        # Group metrics by type
        offensive_metrics = {k: v for k, v in metrics.items() if 'off' in k.lower()}
        defensive_metrics = {k: v for k, v in metrics.items() if 'def' in k.lower()}
        other_metrics = {k: v for k, v in metrics.items() if k not in offensive_metrics and k not in defensive_metrics}

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Offensive Metrics**")
            for metric_name, metric_data in list(offensive_metrics.items())[:3]:
                clean_name = metric_name.replace('_rapm_5v5', '').replace('_', ' ').title()
                value = metric_data.get('value', 0)
                percentile = metric_data.get('percentile', None)

                st.metric(
                    clean_name,
                    f"{value:+.3f}",
                    f"{percentile:.0f}th percentile" if percentile else None
                )

        with col2:
            st.markdown("**Defensive Metrics**")
            for metric_name, metric_data in list(defensive_metrics.items())[:3]:
                clean_name = metric_name.replace('_rapm_5v5', '').replace('_', ' ').title()
                value = metric_data.get('value', 0)
                percentile = metric_data.get('percentile', None)

                st.metric(
                    clean_name,
                    f"{value:+.3f}",
                    f"{percentile:.0f}th percentile" if percentile else None
                )

        with col3:
            st.markdown("**Special Metrics**")
            for metric_name, metric_data in list(other_metrics.items())[:3]:
                clean_name = metric_name.replace('_rapm_5v5', '').replace('_', ' ').title()
                value = metric_data.get('value', 0)
                percentile = metric_data.get('percentile', None)

                st.metric(
                    clean_name,
                    f"{value:+.3f}",
                    f"{percentile:.0f}th percentile" if percentile else None
                )
    else:
        st.info("Advanced RAPM metrics not available for this player yet. This player may not have sufficient ice time in our current dataset.")

    st.divider()

    # Career Timeline Preview
    st.subheader("Career Progression Preview")
    st.info("""
    **Coming Soon with Full Dataset:**
    - RAPM progression over seasons with confidence intervals
    - Latent skill development (Play Driver, Elite Shutdown, etc.)
    - DLM forecasts for future performance
    - Trend analysis and stability indicators
    """)

    # Sample chart placeholder
    if len(metrics) > 0:
        st.caption("Sample career trajectory (mock data):")
        chart_data = pd.DataFrame({
            'season': ['2020-21', '2021-22', '2022-23', '2023-24', '2024-25'],
            'performance': [0.5, 0.8, 1.2, 0.9, 1.1]
        })
        st.line_chart(chart_data.set_index('season'))

    # Advanced Features Preview
    st.subheader("Advanced Features (Data Scaling In Progress)")

    tab1, tab2, tab3 = st.tabs(["Teammate Impact", "Line Chemistry", "Advanced Attribution"])

    with tab1:
        st.info("**Teammate Impact Analysis:** Quantify how this player affects teammates' performance through plus/minus changes and RAPM adjustments.")

    with tab2:
        st.info("**Line Chemistry:** Identify optimal line combinations and measure chemistry effects on performance.")

    with tab3:
        st.info("**Advanced Attribution:** Beyond goals/assists - xG creation, zone entries, possession impact, and secondary assists.")

    st.divider()

    # Feedback Section
    st.subheader("Help Shape Our Analytics")
    st.markdown("""
    This is early access - your feedback matters! What would you like to see for this player?
    What questions do these metrics help answer?
    """)

    feedback = st.text_area("Your feedback:", height=100, placeholder="What analytics would be most valuable to you?")
    if st.button("Submit Feedback"):
        if feedback.strip():
            st.success("Thank you for your feedback! We'll use it to prioritize features.")
        else:
            st.warning("Please enter some feedback before submitting.")

def show_analytics_explanation():
    """Explain the analytics methodology."""

    st.header("Understanding Our Analytics")

    st.markdown("""
    ### What Makes Our Analytics Different

    Traditional hockey stats focus on counting (goals, assists, shots).
    Our advanced analytics use **machine learning** to measure player impact.
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("RAPM (Regularized Adjusted Plus-Minus)")
        st.markdown("""
        - Measures how much a player contributes to goal differential
        - Adjusts for teammates and opponents
        - Uses ridge regression for statistical rigor
        - Per-60 minute rates for fair comparisons
        """)

    with col2:
        st.subheader("Latent Skills (AI-Powered)")
        st.markdown("""
        - Uses Sparse Autoencoder to find hidden player traits
        - Examples: "Play Driver", "Elite Shutdown", "Transition Killer"
        - Learns patterns from 14+ RAPM metrics
        - Provides deeper player understanding
        """)

    st.subheader("Current Limitations & Improvements")

    st.warning("""
    **Current Challenges:**
    - Only 53 games analyzed (4% of NHL season)
    - Minimum ice time requirements not always met
    - Some models still learning from limited data

    **Solutions In Progress:**
    - Scaling to 130-260 games (50-60% credibility improvement)
    - Full season data (1300 games = 85% credibility)
    - Quality filters and validation systems
    """)

    st.subheader("Credibility Ratings")

    st.markdown("""
    | Credibility | Meaning | Trust Level |
    |-------------|---------|-------------|
    | 0-30% | Developing | Use for trends only |
    | 30-70% | Moderate | Good for analysis |
    | 70-90% | High | Very reliable |
    | 90%+ | Professional | Industry standard |
    """)

def show_roadmap():
    """Show product roadmap and timeline."""

    st.header("Product Roadmap")

    st.markdown("""
    ### Phase 1: MVP Launch (Next 2-4 Weeks)
    - âœ… Advanced analytics backend complete
    - ðŸ”„ Basic player profiles and search
    - ðŸ”„ Career timeline charts (EvanMiya style)
    - ðŸ”„ Credibility transparency features

    ### Phase 2: Data Scaling (1-3 Months)
    - ðŸ“Š 130-260 games (50-60% credibility)
    - ðŸ¤– Improved latent skill models
    - ðŸ“ˆ Enhanced forecasting accuracy
    - ðŸ‘¥ Teammate impact analysis

    ### Phase 3: Full Features (3-6 Months)
    - ðŸ“Š Complete season data (85% credibility)
    - ðŸ”— Line chemistry optimization
    - ðŸŽ¯ Advanced attribution models
    - ðŸ“± Mobile app and premium features
    """)

    st.subheader("Success Metrics")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("User Engagement", "Target: 5+ min sessions")
    with col2:
        st.metric("Credibility Rating", "Current: 20% â†’ Target: 85%")
    with col3:
        st.metric("Data Coverage", "Current: 53 â†’ Target: 1300 games")

if __name__ == "__main__":
    main()